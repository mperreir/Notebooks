{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oculométrie et attention visuelle\n",
    "\n",
    "Bienvenu dans ce notebook dédié à l'étude des données d'oculométrie et aux modèles d'attention visuelle.\n",
    "\n",
    "## Un peu d'intuition\n",
    "\n",
    "Exécutez le code ci-dessous qui affiche simplement les différentes images (stimuli) qui ont été visualisées par des observateurs / fournies en entrée de modèles d'attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "\n",
    "for i in range(1,12):\n",
    "    img=io.imread(\"Stimuli/img\"+str(i)+\".jpg\")\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** A votre avis, quels sont les élements de chaque image qui vont attirer le regard des observateurs ?\n",
    "\n",
    "**Réponse 1:**\n",
    "\n",
    "## Observons la vérité terrain\n",
    "\n",
    "Le script suivant affiche en plus des images (stimuli) les cartes de saillance construites à partir des données oculométriques des observateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,12):\n",
    "    img=io.imread(\"Stimuli/img\"+str(i)+\".jpg\")\n",
    "    sal=io.imread(\"GroundTruthMaps/gt_sal\"+str(i)+\".jpg\")\n",
    "    plt.figure()\n",
    "    plt.subplot(121) # 121 = 1 ligne, 2 colonnes, 1ère sous figure\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122) # 121 = 1 ligne, 2 colonnes, 1ère sous figure\n",
    "    plt.imshow(sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Quels sont les éléments / caractéristique d'image qui attirent le regard des observateurs ? Est-ce que ce ces observations confirment vos intutions de la question 1 ?\n",
    "\n",
    "**Réponse 2:**\n",
    "\n",
    "## Observation des performance d'un modèle d'attention\n",
    "\n",
    "Le script ci-dessous permet de mesure la performance d'un modèle d'attention en utilisant un certain nombre de mesure (Corrélation, AUC, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.transform as tr\n",
    "import sys\n",
    "from pysaliency.benchmark import metrics\n",
    "\n",
    "model_name=\"center-model\"\n",
    "\n",
    "# {Metric name:\n",
    "#   func,\n",
    "#   passes: should we compute 1vs2 and 2vs1 then average?\n",
    "#   type: requires fixation or saliency maps as comparison\n",
    "# }\n",
    "metrics = {\n",
    "    \"AUC_Judd\": [metrics.AUC_Judd, 1, 'fix'], # Binary fixation map\n",
    "    \"AUC_Borji\": [metrics.AUC_Borji, 1, 'fix'], # Binary fixation map\n",
    "    \"NSS\": [metrics.NSS, 1, 'fix'], # Binary fixation map\n",
    "    \"CC\": [metrics.CC, 1, 'sal'], # Saliency map\n",
    "    \"SIM\": [metrics.SIM, 1, 'sal'], # Saliency map\n",
    "    \"KLD\": [metrics.kld, 2, 'sal'] } # Saliency map\n",
    "\n",
    "M = {m:[] for m in metrics.keys()}\n",
    "\n",
    "print(\"Processing\",end=\"\")\n",
    "for im_number in range(1,12):\n",
    "\n",
    "    print(\".\",end=\"\")\n",
    "\n",
    "    # Load fixation and saliency maps from ground truth\n",
    "\n",
    "    sal_gt = { \n",
    "        \"fix\": np.transpose(np.load(\"./GroundTruthData/I\" + str(im_number) + \"_C0.npz\")[\"arr_0\"]),\n",
    "        \"sal\": np.transpose(np.load(\"./GroundTruthData/I\" + str(im_number) + \"_C0_saliency.npz\")[\"arr_0\"])\n",
    "        }\n",
    "\n",
    "    (height, width) = sal_gt[\"sal\"].shape\n",
    "\n",
    "    # Load saliency maps from model\n",
    "    sal_model = io.imread(\"./SalModelsOutputs/\"+ model_name + \"/sal_map_img\" + str(im_number) + \".jpg\" )\n",
    "    sal_model = tr.resize(sal_model, (height, width))\n",
    "\n",
    "    # Normalize data and resize models output\n",
    "    sal_model = np.divide(sal_model, np.sum(sal_model))\n",
    "    sal_gt[\"sal\"] = np.divide(sal_gt[\"sal\"], np.sum(sal_gt[\"sal\"]))\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        func = metrics[metric]\n",
    "        if func[1] == 2:\n",
    "            m  = func[0](sal_model, sal_gt[func[2]])\n",
    "            m += func[0](sal_gt['sal'], sal_model)\n",
    "            m /= 2\n",
    "        else:\n",
    "            m = func[0](sal_model, sal_gt[func[2]])\n",
    "\n",
    "        M[metric].append(m)\n",
    "      \n",
    "print(\"\\nPer image results\\n\")\n",
    "for kk, vv in M.items():\n",
    "    print(\"{:10} : {}\".format(kk, [\"{: .2f}\".format(number) for number in vv]))\n",
    "    \n",
    "print(\"\\nMean/StdDev\\n\")\n",
    "for kk, vv in M.items():\n",
    "    print(\"{:10} : {:.2f} / {:.2f}\".format(kk,np.mean(vv), np.std(vv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque (groupe d') étudiant travaillera sur un modèle particulier. Veuillez adapter la variable `model_name` au nom du modèle que vous étudiez.\n",
    "\n",
    "**Question 3:** Le modèle a-t-il les mêmes performances sur toutes les images ? Essayez d'expliquer pourquoi le modèle se comporte moins bien dans certaines situations.\n",
    "\n",
    "**Réponse 3:**\n",
    "\n",
    "**Question 4:** Les différentes mesures utilisée ont elles des résultats cohérents ? Quelles sont les conséquences pour l'analyse des performances d'un modèle ?\n",
    "\n",
    "**Réponse 4:**\n",
    "\n",
    "**Question 5:** Votre modèle a-t-il les mêmes performances sur toutes les images ? Quels sont les types / caractéristiques d'images sur lesquel le modèle fonctionne bien (ou mal) ?\n",
    "\n",
    "**Réponse 5:**\n",
    "\n",
    "**Question 6:** Comparez les performances de votre modèle avec celles des autres (étudiés par d'autres étudiants). Certains modèles sont ils plus performants que d'autres ? Lesquels ? Le sont ils sur toutes les images ?\n",
    "\n",
    "**Réponse 6:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
